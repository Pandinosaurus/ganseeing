{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, copy\n",
    "from seeing import nethook, setting, show, renormalize, zdataset, pbar\n",
    "from seeing import encoder_net\n",
    "from seeing import imgviz, segmenter\n",
    "from torchvision import models\n",
    "from torch.nn.functional import mse_loss, l1_loss\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'church'\n",
    "image_number = 883\n",
    "loaded_image, _ = setting.load_test_image(image_number, 'train', model)\n",
    "show([image_number, renormalize.as_image(loaded_image[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_residuals(target_x, optimize_over=None, num_steps=3000, show_every=500,\n",
    "                       lr=0.01, milestones=[800, 1200, 1800], model='church'):\n",
    "    if optimize_over is None:\n",
    "        optimize_over = ['layer1', 'layer2', 'layer3']\n",
    "    layernums = [name.replace('layer', '') for name in optimize_over]\n",
    "    show.reset()\n",
    "    \n",
    "    # Load a GAN generator, a trained encoder, and a pretrained VGG.\n",
    "    unwrapped_G = setting.load_proggan(model)\n",
    "    E = setting.load_proggan_inversion(model)\n",
    "    vgg = models.vgg16(pretrained=True)\n",
    "    VF = nethook.subsequence(vgg.features, last_layer='20')\n",
    "    \n",
    "    # Move models and data to GPU\n",
    "    for m in [unwrapped_G, E, VF]:\n",
    "        m.cuda()\n",
    "    \n",
    "    # Some constants\n",
    "    with torch.no_grad():\n",
    "        init_z = E(target_x)\n",
    "        target_v = VF(target_x)\n",
    "        \n",
    "    # Wrap the GAN in an instrumented model that adds residuals at the requested layer\n",
    "    G = encoder_net.ResidualGenerator(copy.deepcopy(unwrapped_G), init_z, optimize_over)\n",
    "    parameters = list(G.parameters(recurse=False))\n",
    "    \n",
    "    # We only need grad over the top-level residual parameters in G.\n",
    "    nethook.set_requires_grad(False, G, E)\n",
    "    nethook.set_requires_grad(True, *parameters)\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, milestones=milestones, gamma=0.5)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        for step_num in pbar(range(num_steps + 1)):\n",
    "            current_x = G()\n",
    "            loss_x = l1_loss(target_x, current_x)\n",
    "            loss_v = mse_loss(target_v, VF(current_x))\n",
    "            loss_d = sum(getattr(G, 'd%s' % n).pow(2).mean() for n in layernums)\n",
    "            loss = loss_x + loss_v + loss_d\n",
    "            if show_every and step_num % show_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    show.a(\n",
    "                        ['step %d' % step_num] +\n",
    "                        ['loss: %f' % loss.item()] +\n",
    "                        ['loss_x: %f' % loss_x.item()] +\n",
    "                        ['loss_v: %f' % loss_v.item()] +\n",
    "                        ['loss_d: %f' % loss_d.item()] +\n",
    "                        [[renormalize.as_image(current_x[0])]], cols=3)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            if step_num > 0:\n",
    "                optimizer.step()\n",
    "        show.flush()\n",
    "    \n",
    "    return current_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconst = optimize_residuals(loaded_image.cuda(), model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = imgviz.ImageVisualizer(256)\n",
    "upp = segmenter.UnifiedParsingSegmenter()\n",
    "\n",
    "show([['original', iv.image(loaded_image)],\n",
    "      ['reconstruction', iv.image(reconst)]])\n",
    "orig_seg = upp.segment_batch(loaded_image.cuda())[0, 0:1]\n",
    "reconst_seg = upp.segment_batch(reconst.cuda())[0, 0:1]\n",
    "\n",
    "show([[iv.segmentation(orig_seg)], [iv.segmentation(reconst_seg)],\n",
    "     iv.segment_key(torch.cat([orig_seg, reconst_seg]), upp)])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}